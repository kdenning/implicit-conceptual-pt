---
title: "Implicit Conceptual PT Data Analysis (for SAP requirement)"
author: "Kathryn Denning"
date: "2/14/2020"
output: 
  html_document:
    code_folding: "show"
    toc: true
    toc_float: true
editor_options: 
  chunk_output_type: console
---

# Introduction to study

This study looked at whether people consider the conceptual perspectives (e.g., likes) of others without conscious awareness, and if this depends on whether the target individual has the same visibility of the target stimuli as them. Participants were asked to respond about how much they liked the stimuli after being trained on the targets' likes and dislikes. Implicit conceptual perspective taking would be found if people are slower to respond on inconsistent trials in comparison to consistent trials.

**Variable names included in the analysis:**

* **consistent**: Whether the participant had the same conceptual perspective as the target or not. Helemert contrasts were applied to this categorical variable. 
  + consistent: perspectives about whether or not they liked the stimuli were the same
  + inconsistent: perspectives were different
  + unknown: the participant does not know the target's perspective
  + dislike: the participant dislikes the stimuli; included as a comparison so that participants were not only responding "like" the entire time
* **visibility**: Whether the target individual can see the food stimuli or not.
* **exp_resp.rt **: Reaction time on trials in seconds.


```{r setup, echo = FALSE, warning = FALSE, message = FALSE, error = FALSE}
# Cleaning
## import data

#install.packages("rio")
#install.packages("here")
#install.packages("tidyverse")
#install.packages("magrittr")
#install.packages("janitor")
#install.packages("lme4")
#install.packages("psy")
#install.packages("irr")
#install.packages("emmeans")
#install.packages("sjPlot")
#install.packages("effects")
#install.packages("fs")
library(rio)
library(here)
library(tidyverse)
library(magrittr)
library(janitor)
library(lme4)
library(psy)
library(irr)
library(sjPlot)
library(emmeans)
library(effects)
library(here)
library(fs)
library(psych)
library(rstatix)  
library(afex)

#Setting global chunk options
knitr::opts_chunk$set(echo = TRUE,
                      message = FALSE,
                      warning = FALSE)
```

```{r combining datasets and cleaning, include = FALSE}
# Getting file names for each individual participants datasets into one character vector
files <- dir_ls(here::here("Data"), glob = "*.csv")

# Reading one dataset in to figure out how I want to clean it
sap1 <- readr::read_csv(file = files[1],
                col_names = TRUE)

# Practice cleaning on one dataset
sap1_sub <- sap1 %>% select(participant, expBlock.thisN, expTrials.thisN, 
                            facing_exp, person_exp, food_exp, showL_R, 
                            consistent, exp_resp.keys, exp_resp.rt) %>% 
  na.omit() %>% 
  mutate(trial_num = as.numeric(row_number()),
         consistent = as.factor(consistent), 
         exp_resp.keys = as.factor(exp_resp.keys),
         food_exp = as.factor(food_exp),
         visibility = as.factor(ifelse(facing_exp == showL_R, 
                                       "same", 
                                       ifelse(facing_exp != showL_R, 
                                              "diff", NA))),
         error = as.factor(ifelse(exp_resp.keys == "up" & food_exp == "y", 
                                  "Error",
                                  ifelse(exp_resp.keys == "down" 
                                         & food_exp == c("g", "d"),
                                         "Error", 
                                         ifelse(exp_resp.keys == "up" 
                                                & food_exp == c("g", "d"), 
                                                "Correct",
                                                ifelse(exp_resp.keys == "down" 
                                                       & food_exp == "y", 
                                                       "Correct", NA))))))
                                  
# Writing a function to clean all the datasets using practice from above
## Only selecting variables we want from the larger Psychopy dataset
## Creating variables for trial number and for whether the target has the same visibility as the participant
clean_sap <- function(file) {
                    sap <- read_csv(file)
                    sap %>% 
                      #selecting the variables relevant to analysis from the dataset
                    select(participant, expBlock.thisN, expTrials.thisN, 
                            facing_exp, person_exp, food_exp, showL_R, 
                            consistent, exp_resp.keys, exp_resp.rt) %>% 
                      na.omit() %>% 
                      # making variables correct form
                      mutate(trial_num = as.numeric(row_number()),
                             consistent = as.factor(consistent),
                             exp_resp.keys = as.factor(exp_resp.keys),
                             food_exp = as.factor(food_exp),
                             # creating a variable for target's ability to see stimuli
                             visibility = as.factor(ifelse(facing_exp == showL_R,
                                                           "Visible", 
                                                           ifelse(facing_exp != showL_R, 
                                                                  "Not Visible", NA))),
                             # making it easier to understand the levels of consistency
                             consistent  = recode(consistent, 
                            `c` = "Consistent",
                            `i` = "Inconsistent",
                            `u` = "Unknown",
                            `y` = "Dislike")) %>% 
                      # filtering out practice block and first trial in each block
                      filter(expBlock.thisN != "0" | expTrials.thisN != "0")
}

# Drop "6_APCT" files because participant never made it to experimental portion and dataset is in different format due to that
files <- grep("/6_ACPT", files, value = TRUE, invert = TRUE)

# Apply function to list of datasets to cycle through and create one overall dataset
data <- map_df(files, clean_sap, .id = "column_names")

# Adding error variable and effects coding visibility
dat_error <- data %>%  
  mutate(error = with(data, ifelse(exp_resp.keys == "up" 
                                   & food_exp == "y", "Error", 
                                   ifelse(exp_resp.keys == "down" 
                                          & food_exp == c("g", "d"), "Error",
                                          "Correct"))),
         visibility_effects = recode(visibility, 
                                      `Visible` = "-.5",
                                      `Not Visible` = ".5"))

# Making error a factor variable
dat_error %<>% mutate(error = as.factor(error)) %>% 
  na.omit()

# Read in demographic info dataset
dem <- read.csv("ACPT_dem.csv", header = TRUE) 

# Fixing error of variable name from read in
dem %<>% rename("participant" = "Ã¯..participant")

# Combine the datasets
data_comb <- left_join(dat_error, dem, by = "participant")

# Checking where there is na data
colnames(data_comb)[colSums(is.na(data_comb)) > 0]

# Creating a separate dataset for analyses from what will be used for demographics to not exclude people who have na's in dem data since dem data was optional
dat_analysis <- data_comb %>% 
  select(participant, trial_num, expBlock.thisN, food_exp, consistent, 
         exp_resp.rt, exp_resp.keys, visibility, visibility_effects, error)
```

# Looking at data

## Checking for outliers and filtering responses over 3 seconds

```{r rt outliers over 3 sec}
# Checking outliers in reaction time overall
hist_rt <- dat_analysis %>% 
  select(participant, exp_resp.rt) %>% 
  unique()
hist(hist_rt$exp_resp.rt, xlim = c(0, 60), breaks = 150)

# Removing trials that took over 3 seconds to respond
data_rt <- dat_analysis %>% 
  filter(exp_resp.rt < 3.0)

# Re-checking for outliers in reaction time overall
hist_rt_3sec <- data_rt %>% 
  select(participant, exp_resp.rt) %>% 
  unique()
hist(hist_rt_3sec$exp_resp.rt, xlim = c(0, 5), breaks = 50)
```

## Percent of trials over 3 sd

```{r}
# percent removed over 3 seconds
(1 - nrow(data_rt)/nrow(dat_analysis))*100
```

## Descriptives before removing error trials

### Mean and SD for reaction time by consistency condition

```{r mean aggregation consist before removing errors}
# aggregating responses per participant
data_aggregated_werror <- data_rt %>% 
  group_by(participant, consistent, visibility) %>% 
  summarize(rt_pagg = mean(exp_resp.rt))

consistency_werror <- data_aggregated_werror %>% 
  select(participant, consistent, rt_pagg) %>% 
  na.omit() %>% 
  group_by(consistent) %>% 
  summarize(mean = mean(rt_pagg),
            sd = sd(rt_pagg),
            se = sd(rt_pagg)/sqrt(length(rt_pagg)))
consistency_werror 
```

### Mean and SD for reaction time by visibility condition

```{r mean aggregation visible before removing errors}
visibility_werror <- data_aggregated_werror %>% 
  select(participant, visibility, rt_pagg) %>% 
  na.omit() %>% 
  group_by(visibility) %>% 
  summarize(mean = mean(rt_pagg),
            sd = sd(rt_pagg),
            se = sd(rt_pagg)/sqrt(length(rt_pagg)))
visibility_werror
```

### Combined table for reaction time with both visibility and consistency with error

```{r mean aggregation combined before error removed}
combined_werror <- data_aggregated_werror %>% 
  select(participant, visibility, consistent, rt_pagg) %>% 
  na.omit() %>% 
  group_by(visibility, consistent) %>% 
  summarize(mean = mean(rt_pagg),
            sd = sd(rt_pagg),
            se = sd(rt_pagg)/sqrt(length(rt_pagg)))
combined_werror
```


### Overall variable descriptives

```{r mean aggregation overall before removing errors}
data_aggregated_werror %>% 
  select(visibility, consistent, rt_pagg) %>% 
  describe()
```

## Descriptives after removing error trials

### Mean and SD for reaction time by consistency condition

```{r mean aggregation consist after removing errors}
data_aggregated_nerror <- data_rt %>% 
  filter(error != "Error") %>%
  droplevels(data_rt$error) %>% 
  na.omit() %>% 
  group_by(participant, consistent, visibility) %>% 
  summarize(rt_pagg = mean(exp_resp.rt))

consistency_nerror <- data_aggregated_nerror %>% 
  select(participant, consistent, rt_pagg) %>% 
  na.omit() %>% 
  group_by(consistent) %>% 
  summarize(mean = mean(rt_pagg),
            sd = sd(rt_pagg),
            se = sd(rt_pagg)/sqrt(length(rt_pagg)))
consistency_nerror 
```

### Mean and SD for reaction time by visibility condition

```{r mean aggregation visible after removing errors}
visibility_nerror <- data_aggregated_nerror %>% 
  select(participant, visibility, rt_pagg) %>% 
  na.omit() %>% 
  group_by(visibility) %>% 
  summarize(mean = mean(rt_pagg),
            sd = sd(rt_pagg),
            se = sd(rt_pagg)/sqrt(length(rt_pagg)))
visibility_nerror
```

### Combined table for reaction time with both visibility and consistency without error

```{r mean aggregation combined error removed}
combined_nerror <- data_aggregated_nerror %>% 
  select(participant, visibility, consistent, rt_pagg) %>% 
  na.omit() %>% 
  group_by(visibility, consistent) %>% 
  summarize(mean = mean(rt_pagg),
            sd = sd(rt_pagg),
            se = sd(rt_pagg)/sqrt(length(rt_pagg)))
combined_nerror
```

### Overall variable descriptives

```{r mean aggregation overall after removing errors}
data_aggregated_nerror %>% 
  select(visibility, consistent, rt_pagg) %>% 
  describe()
```

## Percent of error trials vs correct trials

```{r percent error}
# Percent error
data_rt %>% 
  select(error) %>% 
  group_by(error) %>% 
  count() %>% 
  mutate(percent = n/(3509+57222)*100)
```

# Model predicting RT

## Contrasts

```{r setup and contrasts}
# Removing dislike condition from anaysis as it was just a methodological variation not theoretically related to analysis
# Removing errors from analysis
anova_rt_data <- data_rt %>% 
  filter(error != "Error") %>% 
  filter(consistent != "Dislike") %>%
  droplevels(data_rt$error) %>% 
  droplevels(data_rt$consistent) %>% 
  na.omit() %>% 
  group_by(participant, consistent, visibility) %>% 
  mutate(rt_pagg = mean(exp_resp.rt)) %>% 
  select(participant, consistent, visibility, visibility_effects, rt_pagg) %>% 
  unique() %>% 
  na.omit()

CIvU <- c(-1, -1, 2) 
CvI <- c(-1, 1, 0) 
ConCodes <- cbind(CIvU, CvI)
contrasts(anova_rt_data$consistent) <- ConCodes
contrasts(anova_rt_data$consistent)
```

*Visibility was effects coded*

## Results

```{r rt anova results}
# Running the repeated measures aov from stats in R
model1 <- with(anova_rt_data, 
               aov(rt_pagg ~ (visibility_effects*consistent) + 
                     Error(participant/(visibility_effects*consistent))))

summary(model1)

# Models using aov_car and aov_ez from package Afex

alt_model1 <- aov_car(rt_pagg ~ Error(participant/(visibility_effects*consistent)),
                      data = anova_rt_data, anova_table = list(p_adjust_method = "bonferroni"))
summary(alt_model1)

#model gets the same results as alternative model 1
alt_model2 <- aov_ez("participant", "rt_pagg", anova_rt_data,
        within = c("visibility_effects", "consistent"),
        anova_table = list(p_adjust_method = "bonferroni"))

summary(alt_model2) #without bonferroni adjustment
nice(alt_model2) #with bonferroni adjustment


# Using emmeans to get marginal means for pairwise comparisons - smooth code for marginal means! These look like what I get when I hard code this by hand using dplyr
mm_consistent_model1 <- emmeans(alt_model1, ~ consistent)

# Tukey pairwise comparisons - what I expected from the plots
pairs(mm_consistent_model1)
```

## Plots

```{r rt consistent no error plot}
# Dropping dislike option from plot
consistency_nerror_ndislike <-  consistency_nerror %>% 
  filter(consistent != "Dislike") %>% 
  droplevels(consistency_nerror$consistent) %>% 
  na.omit()

ggplot(consistency_nerror_ndislike, aes(x = consistent, y = mean, fill = consistent)) +
  geom_bar(stat = "identity") +
  theme_minimal() +
  scale_fill_viridis_d() +
  theme(legend.position = "none") +
  labs(title = "Reaction time predicted by perspective consistency",
       subtitle = "Response error has been removed",
       x = "Perspective consistency condition",
       y = "Reaction time (seconds)") +
  geom_errorbar(aes(ymin = mean - se, ymax = mean + se), width = .2,
                position = position_dodge(.9)) 
```

```{r rt visibility no error plot}
ggplot(visibility_nerror , aes(x = visibility, y = mean, fill = visibility)) +
  geom_bar(stat = "identity") +
  theme_minimal() +
  scale_fill_viridis_d() +
  theme(legend.position = "none") +
  labs(title = "Reaction time predicted by visibility",
       subtitle = "Response error has been removed",
       x = "Visibility condition",
       y = "Reaction time (seconds)") +
  geom_errorbar(aes(ymin = mean - se, ymax = mean + se), width = .2,
                position = position_dodge(.9)) 
```

# Model predicting error

## Contrasts

```{r error setup}
# Organizing data to include both levels of error but get rid of the dislike condition
anova_error_data <- data_rt %>% 
  filter(consistent != "Dislike") %>%
  droplevels(data_rt$consistent) %>% 
  na.omit() %>% 
  group_by(participant, visibility_effects, consistent, error) %>% 
  unique() %>% 
  count() %>% 
  mutate(n_per_grouping = n)

anova_error_data2 <- anova_error_data %>% 
  group_by(participant) %>% 
  mutate(n_per_total = sum(n_per_grouping)) %>% 
  mutate(n_per_grouping = ifelse(error == "Correct", 0, ifelse(error == "Error", n_per_grouping, NA))) %>% 
  mutate(error_per_group = (n_per_grouping/n_per_total)*100)

anova_error_data3 <- anova_error_data2 %>% 
  group_by(participant, visibility_effects, consistent) %>% 
  mutate(error_rate = mean(error_per_group)) %>% 
  select(participant, visibility_effects, consistent, error_rate) %>% 
  unique()

# Applying helmert contrasts to consistent; visibility is already effects coded
contrasts(anova_error_data3$consistent) <- ConCodes
contrasts(anova_error_data3$consistent)
```

*Visibility was effects coded*

## Anova results predicting error

```{r}
# Running logistic regression predicting error
model2 <- with(anova_error_data3,
                  aov(error_rate ~ (visibility_effects*consistent) +
                        Error(participant/(visibility_effects*consistent))))


summary(model2)
```

## Plot and descriptives for main effect of consistency

```{r error main effect consist}
data_aggregated_errorrate <- anova_error_data3 %>% 
  select(participant, consistent, error_rate) %>% 
  na.omit() %>% 
  group_by(consistent) %>% 
  summarize(mean = mean(error_rate),
            sd = sd(error_rate),
            se = sd(error_rate)/sqrt(length(error_rate)))
data_aggregated_errorrate 


ggplot(data_aggregated_errorrate, aes(x = consistent, y = mean, fill = consistent)) +
  geom_bar(stat = "identity") +
  theme_minimal() +
  scale_fill_viridis_d() +
  theme(legend.position = "none") +
  labs(title = "Error rate predicted by perspective consistency",
       x = "Perspective consistency condition",
       y = "Error rate (out of 100%)") +
  geom_errorbar(aes(ymin = mean - se, ymax = mean + se), width = .2,
                position = position_dodge(.9)) 
```

## Descriptives for visibility

```{r error rate visibility descrip}
data_aggregated_errorrate_vis <- anova_error_data3 %>% 
  select(participant, visibility_effects, error_rate) %>% 
  na.omit() %>% 
  group_by(visibility_effects) %>% 
  summarize(mean = mean(error_rate),
            sd = sd(error_rate),
            se = sd(error_rate)/sqrt(length(error_rate)))
data_aggregated_errorrate_vis 
```

# Model predicting RT with block as predictor

```{r setup and contrasts rt with block}
# Removing dislike condition from anaysis as it was just a methodological variation not theoretically related to analysis
# Removing errors from analysis
anova_rt_block_data <- data_rt %>% 
  filter(error != "Error") %>% 
  filter(consistent != "Dislike") %>%
  droplevels(data_rt$error) %>% 
  droplevels(data_rt$consistent) %>% 
  na.omit() %>% 
  group_by(participant, consistent, visibility, expBlock.thisN) %>% 
  mutate(rt_pagg = mean(exp_resp.rt)) %>% 
  select(participant, consistent, visibility, visibility_effects, rt_pagg, expBlock.thisN) %>% 
  unique() %>% 
  na.omit()

CIvU <- c(-1, -1, 2) 
CvI <- c(-1, 1, 0) 
ConCodes <- cbind(CIvU, CvI)
contrasts(anova_rt_block_data$consistent) <- ConCodes
contrasts(anova_rt_block_data$consistent)
```

*Visibility was effects coded*

## Results

```{r rt anova results block}
# Running the repeated measures anova
model3 <- with(anova_rt_block_data, 
               aov(rt_pagg ~ (visibility_effects*consistent*expBlock.thisN) + 
                     Error(participant/(visibility_effects*consistent*expBlock.thisN))))
summary(model3)
```


## Plot for consistency

```{r plot block model for consistency}
# Plot for consistency
block_model_rt_consistent <- anova_rt_block_data %>% 
  select(participant, consistent, rt_pagg) %>% 
  na.omit() %>% 
  group_by(consistent) %>% 
  summarize(mean = mean(rt_pagg),
            sd = sd(rt_pagg),
            se = sd(rt_pagg)/sqrt(length(rt_pagg)))

ggplot(block_model_rt_consistent, aes(x = consistent, y = mean, fill = consistent)) +
  geom_bar(stat = "identity") +
  theme_minimal() +
  scale_fill_viridis_d() +
  theme(legend.position = "none") +
  labs(title = "Reaction time predicted by perspective consistency",
       subtitle = "Response error has been removed",
       x = "Perspective consistency condition",
       y = "Reaction time (seconds)") +
  geom_errorbar(aes(ymin = mean - se, ymax = mean + se), width = .2,
                position = position_dodge(.9)) 
```

## Plot for block

```{r plot block model for block}
# Plot for consistency
block_model_rt_block <- anova_rt_block_data %>% 
  select(participant, expBlock.thisN, rt_pagg) %>% 
  na.omit() %>% 
  group_by(expBlock.thisN) %>% 
  summarize(mean = mean(rt_pagg),
            sd = sd(rt_pagg),
            se = sd(rt_pagg)/sqrt(length(rt_pagg)))

ggplot(block_model_rt_block, aes(x = expBlock.thisN, 
                                      y = mean, 
                                      fill = expBlock.thisN)) +
  geom_line() +
  theme_minimal() +
  theme(legend.position = "none") +
  labs(title = "Reaction time predicted by block number",
       subtitle = "Response error has been removed",
       x = "Block number",
       y = "Reaction time (seconds)") +
  geom_errorbar(aes(ymin = mean - se, ymax = mean + se), width = .2,
                position = position_dodge(.9)) 
```

# Model predicting error with block as predictor

```{r error block setup}
# Organizing data to include bothlevels of error but get rid of the dislike condition
anova_error_data_block <- data_rt %>% 
  filter(consistent != "Dislike") %>%
  droplevels(data_rt$consistent) %>% 
  na.omit() %>% 
  group_by(participant, visibility_effects, consistent, error, expBlock.thisN) %>% 
  unique() %>% 
  count() %>% 
  mutate(n_per_grouping = n)

anova_error_data_block2 <- anova_error_data_block %>% 
  group_by(participant, expBlock.thisN) %>% 
  mutate(n_per_total = sum(n_per_grouping))

anova_error_data_block3 <- anova_error_data_block2 %>% 
  mutate(n_per_grouping = ifelse(error == "Correct", 0, ifelse(error == "Error", n_per_grouping, NA))) %>% 
  mutate(error_per_group = (n_per_grouping/n_per_total)*100)

anova_error_data_block4 <- anova_error_data_block3 %>% 
  group_by(participant, visibility_effects, consistent, expBlock.thisN) %>% 
  mutate(error_rate = mean(error_per_group)) %>% 
  select(participant, visibility_effects, consistent, error_rate, expBlock.thisN) %>% 
  unique()

# Applying helmert contrasts to consistent; visibility is already effects coded
contrasts(anova_error_data_block3$consistent) <- ConCodes
contrasts(anova_error_data_block3$consistent)
```

## Anova Results

```{r}
# Running logistic regression predicting error
model4 <- with(anova_error_data_block4,
                  aov(error_rate ~ (visibility_effects*consistent*expBlock.thisN) +
                        Error(participant/(visibility_effects*consistent*expBlock.thisN))))


summary(model4)
```

Does not change results, only the main effect of consistency is significant.

## Descriptives for consistency

```{r error rate consist descrip block}
data_aggregated_errorrate_block_con <- anova_error_data_block4 %>% 
  select(participant, consistent, error_rate) %>% 
  na.omit() %>% 
  group_by(consistent) %>% 
  summarize(mean = mean(error_rate),
            sd = sd(error_rate),
            se = sd(error_rate)/sqrt(length(error_rate)))
data_aggregated_errorrate_block_con 
```

## Descriptives for visibility

```{r error rate visibility descrip block}
data_aggregated_errorrate_block_vis <- anova_error_data_block4 %>% 
  select(participant, visibility_effects, error_rate) %>% 
  na.omit() %>% 
  group_by(visibility_effects) %>% 
  summarize(mean = mean(error_rate),
            sd = sd(error_rate),
            se = sd(error_rate)/sqrt(length(error_rate)))
data_aggregated_errorrate_block_vis 
```
# Demographics

## Number of participants with demographic data

```{r participant number}
data_comb %>% 
  select(participant) %>% 
  unique() %>% 
  nrow()
```

## Gender

```{r gender}
data_comb %>% 
  select(participant, gender) %>% 
  na.omit() %>% 
  unique() %>% 
  group_by(gender) %>% 
  count()
```

## Race

```{r race}
race1 <- data_comb %>% 
  select(participant, race) %>% 
  na.omit() %>% 
  unique() %>% 
  group_by(race) %>% 
  count()

race1 %>% 
  mutate(total_n = sum(race1$n[1:7])) %>% 
  mutate(percent = n/total_n*100)
```

## Age

```{r age}
data_comb %>% 
  select(participant, age) %>% 
  na.omit() %>% 
  summarize(mean = mean(age),
            sd = sd(age))
```

## Class level

```{r class level}
data_comb %>% 
  select(participant, class_level) %>% 
  na.omit() %>% 
  unique() %>% 
  group_by(class_level) %>% 
  count()
```

## Parent's education

```{r parents education}
data_comb %>% 
  select(participant, parents_edu) %>% 
  na.omit() %>% 
  unique() %>% 
  group_by(parents_edu) %>% 
  count()
```

## Native language

```{r native language}
data_comb %>% 
  select(participant, english_native) %>% 
  na.omit() %>% 
  unique() %>% 
  group_by(english_native) %>% 
  count()
```

## Born in the US

```{r birth country}
data_comb %>% 
  select(participant, us_birth_country) %>% 
  na.omit() %>% 
  unique() %>% 
  group_by(us_birth_country) %>% 
  count()
```

## Raised in the US

```{r country raised in}
data_comb %>% 
  select(participant, us_raised) %>% 
  na.omit() %>% 
  unique() %>% 
  group_by(us_raised) %>% 
  count()
```

```{r, include = FALSE}
## MLM version - only runs as a fixed effects model not random effects, which isn't what we want
mlm_data <- dat_analysis %>% 
  filter(error != "Error") %>% 
  filter(consistent != "Dislike") %>%
  droplevels(data_rt$error) %>% 
  droplevels(data_rt$consistent) %>% 
  na.omit() %>% 
  select(participant, consistent, visibility, visibility_effects, exp_resp.rt, trial_num) %>% 
  unique() %>% 
  na.omit()

contrasts(mlm_data$consistent) <- ConCodes
contrasts(mlm_data$consistent)

mlm_model <- lmer(exp_resp.rt ~ consistent*visibility_effects + (1 | participant), mlm_data)

tab_model(mlm_model,
          title = "MLM model predicting reaction time")
```


```{r setup rt with timeout, include = FALSE}
# Reaction time model including SD in RT as a predictor
## Contrasts for consistency


# Getting SD to make categorical variable by SD
describe(dat_analysis$exp_resp.rt)

# Removing dislike condition from anaysis as it was just a methodological variation not theoretically related to analysis
# Removing errors from analysis
# Creating categorical predictor for SD
anova_timeout <- dat_analysis %>% 
  mutate(timeout = with(dat_analysis, ifelse(exp_resp.rt < (1.93), 
                                              "Average", 
                                              ifelse(exp_resp.rt > (1.93) & exp_resp.rt < (3.06), "1 SD above", 
                                                     ifelse(exp_resp.rt > (3.06) & exp_resp.rt < (4.19), "2 SD above", NA))))) %>% 
  filter(error != "Error") %>% 
  filter(consistent != "Dislike") %>%
  droplevels(data_rt$error) %>% 
  droplevels(data_rt$consistent) %>% 
  na.omit()  %>% 
  mutate(timeout = as.factor(timeout)) %>% 
  group_by(participant, consistent, visibility, timeout) %>% 
  mutate(rt_pagg = mean(exp_resp.rt)) %>% 
         #timeout_effects = recode(timeout,
                                  #`Less than 3 seconds` = "-.5",
                                  #`More than 3 seconds` = ".5")) %>% 
  select(participant, consistent, visibility, visibility_effects, 
         rt_pagg, timeout) %>% 
  unique() %>% 
  na.omit()

# Applying helmert contrasts to consistent; visibility is already effects coded
contrasts(anova_timeout$consistent) <- ConCodes
contrasts(anova_timeout$consistent)

contrasts(anova_timeout$timeout)


## Anova results

# Running the repeated measures anova
model_timeout <- with(anova_timeout, 
               aov(rt_pagg ~ (visibility_effects*consistent*timeout) + 
                     Error(participant/(visibility_effects*consistent*timeout))))
summary(model_timeout)

## Plot predicting reaction time by SD group of reaction time
consistent_timeout <- anova_timeout %>% 
  select(participant, consistent, rt_pagg, timeout) %>% 
  na.omit() %>% 
  group_by(consistent, timeout) %>% 
  summarize(mean = mean(rt_pagg),
            sd = sd(rt_pagg),
            se = sd(rt_pagg)/sqrt(length(rt_pagg)))

ggplot(consistent_timeout, aes(x = timeout, y = mean, fill = consistent, group = consistent)) +
  geom_bar(stat = "identity", position = "dodge") +
  theme_minimal() +
  scale_fill_viridis_d() +
  theme(legend.position = "right") +
  labs(title = "Reaction time predicted by consistency and time grouping",
       subtitle = "Response error has been removed",
       x = "Time grouping by SD",
       y = "Reaction time (seconds)") +
  geom_errorbar(aes(ymin = mean - se, ymax = mean + se), width = .5,
                position = position_dodge(.9)) 
```